{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4382eca4",
   "metadata": {},
   "source": [
    "# PowerPulse — Household Energy Usage Forecast\n",
    "\n",
    "This notebook combines **EDA → Preprocessing → Feature Engineering → Modeling → Evaluation** for the provided dataset. It loads the dataset from `/mnt/data/data_set.csv`.\n",
    "\n",
    "**Author:** Generated by ChatGPT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80fd3b",
   "metadata": {},
   "source": [
    "## 0. Dependencies & Setup\n",
    "\n",
    "Install packages (run in terminal if needed):\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm joblib statsmodels missingno jupyter\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537512e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35df992",
   "metadata": {},
   "source": [
    "## 1. Load dataset\n",
    "\n",
    "We load the dataset from the provided path: `/mnt/data/data_set.csv`. If your environment differs, update the path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e630d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (2075259, 10)\n",
      "['Unnamed: 0', 'Date', 'Time', 'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date      Time Global_active_power Global_reactive_power  \\\n",
       "0           0  16/12/2006  17:24:00               4.216                 0.418   \n",
       "1           1  16/12/2006  17:25:00               5.360                 0.436   \n",
       "2           2  16/12/2006  17:26:00               5.374                 0.498   \n",
       "3           3  16/12/2006  17:27:00               5.388                 0.502   \n",
       "4           4  16/12/2006  17:28:00               3.666                 0.528   \n",
       "\n",
       "   Voltage Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
       "0  234.840           18.400          0.000          1.000            17.0  \n",
       "1  233.630           23.000          0.000          1.000            16.0  \n",
       "2  233.290           23.000          0.000          2.000            17.0  \n",
       "3  233.740           23.000          0.000          1.000            17.0  \n",
       "4  235.680           15.800          0.000          1.000            17.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to dataset\n",
    "PATH = \"data_set.csv\"\n",
    "\n",
    "# Load\n",
    "try:\n",
    "    df = pd.read_csv(PATH, low_memory=False)\n",
    "    print('Loaded dataset shape:', df.shape)\n",
    "except Exception as e:\n",
    "    print('Failed to load dataset from', PATH)\n",
    "    raise e\n",
    "\n",
    "# Show columns & head\n",
    "print(df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47fdba",
   "metadata": {},
   "source": [
    "## 2. Initial cleaning & datetime parsing\n",
    "\n",
    "Try to parse `Date` and `Time` columns (if available). Otherwise attempt to find a datetime-like column and set index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Combine Date & Time if present\n",
    "if 'Date' in df_clean.columns and 'Time' in df_clean.columns:\n",
    "    df_clean['datetime'] = pd.to_datetime(df_clean['Date'].astype(str) + ' ' + df_clean['Time'].astype(str), dayfirst=True, errors='coerce')\n",
    "    df_clean = df_clean.set_index('datetime').sort_index()\n",
    "else:\n",
    "    # try to parse any single datetime-like column\n",
    "    parsed_col = None\n",
    "    for col in df_clean.columns:\n",
    "        try:\n",
    "            parsed = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "            if parsed.notna().sum() > 0 and parsed.dtype == 'datetime64[ns]':\n",
    "                parsed_col = col\n",
    "                df_clean = df_clean.set_index(parsed).sort_index()\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "if df_clean.index.name is None:\n",
    "    df_clean.index.name = 'datetime'\n",
    "\n",
    "print('Index name:', df_clean.index.name)\n",
    "print('Index sample:', df_clean.index[:3])\n",
    "\n",
    "# Convert numeric columns stored as objects\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype == object:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col].astype(str).str.replace(',', '.').str.strip(), errors='coerce')\n",
    "\n",
    "print('After conversion, numeric cols:', df_clean.select_dtypes(include=['number']).columns.tolist())\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab67a7",
   "metadata": {},
   "source": [
    "## 3. Missing values & basic statistics\n",
    "\n",
    "Show missing values, basic stats, and visualize missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clean.isna().sum())\n",
    "\n",
    "# Basic stats for numeric columns\n",
    "display(df_clean.describe().T)\n",
    "\n",
    "# Visualize missingness (may be heavy for large datasets)\n",
    "try:\n",
    "    msno.matrix(df_clean.sample(frac=min(1.0, 10000/len(df_clean))))\n",
    "    plt.title('Missingness matrix (sample)')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('missingno failed:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7169e5",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Univariate distributions and time-series trends. We'll focus on `Global_active_power` if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df_clean.select_dtypes(include=['number']).columns.tolist()\n",
    "num_cols\n",
    "\n",
    "# Plot distributions for key numeric columns (top 6)\n",
    "for col in num_cols[:6]:\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.histplot(df_clean[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribution: {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Time series trend for Global_active_power\n",
    "if 'Global_active_power' in df_clean.columns:\n",
    "    series = df_clean['Global_active_power'].dropna().resample('H').mean()\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.plot(series.index, series.values)\n",
    "    plt.title('Global_active_power (hourly mean)')\n",
    "    plt.ylabel('kW')\n",
    "    plt.show()\n",
    "\n",
    "    # seasonal decomposition (use 24-hour period)\n",
    "    try:\n",
    "        dec = seasonal_decompose(series.fillna(method='ffill'), model='additive', period=24)\n",
    "        fig = dec.plot()\n",
    "        fig.set_size_inches(12,9)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print('Seasonal decomposition failed:', e)\n",
    "else:\n",
    "    print('Global_active_power not in columns; skip time series plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e216c7c",
   "metadata": {},
   "source": [
    "## 5. Preprocessing\n",
    "\n",
    "Steps: resample to hourly, interpolate missing values, cap outliers using IQR. Save preprocessed CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1091653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df_clean.copy()\n",
    "# Resample to hourly mean\n",
    "try:\n",
    "    df_proc = df_proc.resample('H').mean()\n",
    "except Exception as e:\n",
    "    print('Resample failed:', e)\n",
    "\n",
    "# Interpolate then ffill/bfill\n",
    "df_proc = df_proc.interpolate(method='time', limit=6)\n",
    "df_proc = df_proc.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Cap outliers (IQR) for numeric columns\n",
    "def cap_iqr(series):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5*iqr\n",
    "    upper = q3 + 1.5*iqr\n",
    "    return series.clip(lower, upper)\n",
    "\n",
    "for c in df_proc.select_dtypes(include=['number']).columns:\n",
    "    df_proc[c] = cap_iqr(df_proc[c])\n",
    "\n",
    "# Save\n",
    "proc_path = '/mnt/data/preprocessed_hourly.csv'\n",
    "df_proc.to_csv(proc_path)\n",
    "print('Saved preprocessed data to', proc_path)\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259dd753",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Create time features, lag features, rolling statistics, and prepare train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df_proc.copy()\n",
    "# Time features\n",
    "if isinstance(df_feat.index, pd.DatetimeIndex):\n",
    "    df_feat['hour'] = df_feat.index.hour\n",
    "    df_feat['day'] = df_feat.index.day\n",
    "    df_feat['dayofweek'] = df_feat.index.dayofweek\n",
    "    df_feat['month'] = df_feat.index.month\n",
    "    df_feat['is_weekend'] = (df_feat['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "# Ensure target exists\n",
    "if 'Global_active_power' not in df_feat.columns:\n",
    "    raise ValueError('Global_active_power not found in preprocessed data. Cannot proceed with modeling.')\n",
    "\n",
    "# Lags and rolling\n",
    "lags = [1,2,3,24]\n",
    "for l in lags:\n",
    "    df_feat[f'lag_{l}'] = df_feat['Global_active_power'].shift(l)\n",
    "\n",
    "roll_windows = [3,6,12,24]\n",
    "for w in roll_windows:\n",
    "    df_feat[f'roll_mean_{w}'] = df_feat['Global_active_power'].rolling(window=w, min_periods=1).mean()\n",
    "    df_feat[f'roll_std_{w}'] = df_feat['Global_active_power'].rolling(window=w, min_periods=1).std().fillna(0)\n",
    "\n",
    "# Drop NA created by lags\n",
    "df_feat = df_feat.dropna()\n",
    "\n",
    "# Train-test split (time-based): last 20% as test\n",
    "split_idx = int(len(df_feat)*0.8)\n",
    "train = df_feat.iloc[:split_idx]\n",
    "test = df_feat.iloc[split_idx:]\n",
    "\n",
    "train.to_csv('/mnt/data/train_features.csv')\n",
    "test.to_csv('/mnt/data/test_features.csv')\n",
    "print('Saved train/test feature CSVs. Train shape:', train.shape, 'Test shape:', test.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6699b",
   "metadata": {},
   "source": [
    "## 7. Modeling\n",
    "\n",
    "Train baseline Linear Regression and Random Forest. Evaluate using RMSE, MAE, R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c86ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Global_active_power'\n",
    "features = [c for c in train.columns if c != target]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(y_true, y_pred):\n",
    "    return dict(RMSE = float(np.sqrt(mean_squared_error(y_true, y_pred))),\n",
    "                MAE = float(mean_absolute_error(y_true, y_pred)),\n",
    "                R2 = float(r2_score(y_true, y_pred)))\n",
    "\n",
    "scores = {\n",
    "    'LinearRegression': eval_model(y_test, pred_lr),\n",
    "    'RandomForest': eval_model(y_test, pred_rf)\n",
    "}\n",
    "\n",
    "scores\n",
    "\n",
    "# Save best model (choose RandomForest by default)\n",
    "model_path = '/mnt/data/best_model_rf.pkl'\n",
    "joblib.dump(rf, model_path)\n",
    "print('Saved model to', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360dee1",
   "metadata": {},
   "source": [
    "## 8. Evaluation & Interpretation\n",
    "\n",
    "Plot Actual vs Predicted, residuals, and feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59781a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(y_test.index, y_test.values, label='Actual')\n",
    "plt.plot(y_test.index, pred_rf, label='Predicted (RF)')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted - Global_active_power')\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test.values - pred_rf\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title('Residual distribution')\n",
    "plt.show()\n",
    "\n",
    "# Feature importances\n",
    "try:\n",
    "    importances = rf.feature_importances_\n",
    "    fi = sorted(zip(features, importances), key=lambda x: x[1], reverse=True)[:20]\n",
    "    names = [x[0] for x in fi]\n",
    "    vals = [x[1] for x in fi]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(names[::-1], vals[::-1])\n",
    "    plt.title('Top feature importances (RF)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Feature importance plotting failed:', e)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('Evaluation metrics:')\n",
    "import json\n",
    "print(json.dumps(scores, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEU_venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
